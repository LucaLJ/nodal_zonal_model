{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pypsa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "period_start = \"2018-01-01\"\n",
    "period_end = \"2018-12-31\"\n",
    "time_start = '{} 00:00:00'.format(period_start)\n",
    "time_end = '{} 23:00:00'.format(period_end)\n",
    "timespan = pd.date_range(start=time_start, end=time_end, freq='H')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pypsa.io:Imported network zonal_1024_cost2018_results_1y_min30percent.nc has buses, carriers, generators, links, loads, storage_units\n"
     ]
    }
   ],
   "source": [
    "#directory = 'D:\\Python\\PyPSA/Luca/nodal_zonal_model/hydro/hpc_results/last_results/hour0/0.5/bids/20/'\n",
    "# directory = 'D:\\Python\\PyPSA/Luca/nodal_zonal_model/hydro/hpc_results/last_results/hour0/{}/{}/{}/'\n",
    "directory = 'D:\\Python\\PyPSA/Luca/nodal_zonal_model/hydro/hpc_results/last_results/hour0/zonal/zonal_1024_cost2018_results_1y_min30percent.nc'\n",
    "n = pypsa.Network(directory)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pypsa.io:Imported network network_merged.nc has buses, carriers, generators, lines, links, loads, storage_units\n"
     ]
    }
   ],
   "source": [
    "# # path_network = os.path.join(path,'network_merged.nc')\n",
    "# path_network = 'D:\\Python\\PyPSA/Luca/nodal_zonal_model/hydro/hpc_results/last_results/hour0/0.5/bids/20/network_merged.nc'\n",
    "# n = pypsa.Network(path_network)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "# total capacity of storage units (max_hours*p_nom)\n",
    "cap = n.storage_units.p_nom*n.storage_units.max_hours\n",
    "# potential to close the gap\n",
    "# i.e. inflow in hour 0 for hydro and p_nom*1hour (including efficiency) for PHS\n",
    "close = dict()\n",
    "for su in n.storage_units.index:\n",
    "    if su.__contains__('hydro'):\n",
    "        close[su] = n.storage_units_t.inflow.loc[timespan[0],su]\n",
    "    elif su.__contains__('PHS'):\n",
    "        close[su] = n.storage_units.p_nom[su]*n.storage_units.efficiency_store[su]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "penalty_list = [17, 19,20,27,28,32, 35]\n",
    "penalty_unit = dict()\n",
    "penalty_unit[17] = 1000\n",
    "penalty_unit[19] = 10\n",
    "penalty_unit[20] = 0\n",
    "penalty_unit[27] = 10\n",
    "penalty_unit[28] = 0\n",
    "penalty_unit[32] = 0\n",
    "penalty_unit[35] = 10\n",
    "penalty_sum = dict()\n",
    "penalty_sum[17] = 1000\n",
    "penalty_sum[19] = 1000\n",
    "penalty_sum[20] = 1000\n",
    "penalty_sum[27] = 10\n",
    "penalty_sum[28] = 10\n",
    "penalty_sum[32] = 0\n",
    "penalty_sum[35] = 40"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "bids_list = [30, 40, 50, 60, 70]#['zonal_shadow', 20, 30, 40, 50, 60, 70]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "# for later\n",
    "# to consolidate results\n",
    "out = dict()\n",
    "\n",
    "# directory = 'D:\\Python\\PyPSA/Luca/nodal_zonal_model/hydro/hpc_results/last_results/hour0/{}/{}/{}/'\n",
    "# transmission_cap = 0.5\n",
    "# bids_or_penalty = 'bids'\n",
    "# combi = 20"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% first do this with folder 20\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "# if bids_or_penalty == 'bids':\n",
    "#     combi_list = bids_list\n",
    "# elif bids_or_penalty == 'penalty':\n",
    "#     combi_list = penalty_list\n",
    "# # for combi in combi_list:\n",
    "#     dir_combi = directory.format(transmission_cap,bids_or_penalty,combi)\n",
    "#     # to consolidate results\n",
    "outputs = []\n",
    "    # # add info of penalty or bid to outputs\n",
    "    # outputs.append(bids_or_penalty)\n",
    "\n",
    "    # read soc data\n",
    "df = n.storage_units_t.state_of_charge\n",
    "    # path = os.path.join(dir_combi,'soc_nodal_1y.csv')\n",
    "    # df = pd.read_csv(path)\n",
    "    # df.snapshot = pd.to_datetime(df.snapshot)\n",
    "    # df = df.set_index('snapshot')\n",
    "    # difference where negative values are corrected for close the gap potential from pumping and inflow\n",
    "diff_corrected = (df.loc[timespan[-1]]-df.loc[timespan[0]])\n",
    "for su in diff_corrected.index:\n",
    "    if diff_corrected[su]<0: # if the discrepancy is negative take into account possible inflows and pumping up to close this gap\n",
    "        diff_corrected[su] = diff_corrected[su] + close[su]\n",
    "        if diff_corrected[su]>0: # if inflow and pumping are not only closing the gap but can make difference positive, set it to 0, not to have too nice results\n",
    "            diff_corrected[su]=0\n",
    "# absolute difference corrected\n",
    "outputs.append(diff_corrected.sum())\n",
    "# mean absolute difference pos and neg\n",
    "outputs.append(diff_corrected.mean())\n",
    "# mean rel difference wrt hour 1 (if hour 1 soc is 0 need to ignore these inf values)\n",
    "outputs.append(((diff_corrected/df.loc[timespan[0]])[np.isfinite(diff_corrected/df.loc[timespan[0]])]).mean())\n",
    "    ### other than soc\n",
    "    # computational time\n",
    "    # read from text file the run times\n",
    "    # text_path = os.path.join(dir_combi,'info.txt')\n",
    "    # with open(text_path) as f:\n",
    "    #     lines = f.readlines()\n",
    "    # for i,line in enumerate(lines):\n",
    "    #     if 'finish' in line:\n",
    "    #         time = float(lines[i+1].strip('\\n'))\n",
    "    # # append run time for main optimization to outputs in s and hours\n",
    "    # outputs.append(time)\n",
    "    # outputs.append(time/60/60)\n",
    "ofv = n.objective\n",
    "    # # read ofv 'corrected'\n",
    "    # path_ofv = os.path.join(dir_combi,'objective_value_sum_1y.txt')\n",
    "    # with open(path_ofv) as f:\n",
    "    #     lines = f.readlines()\n",
    "    #     ofv= float(lines[0].strip('\\n'))\n",
    "outputs.append(ofv)\n",
    "\n",
    "    # # more results only if optimization was feasible\n",
    "    # if ofv == np.inf:\n",
    "    #     pass\n",
    "    # else:\n",
    "    #     path_n = os.path.join(dir_combi, 'network_merged.nc')\n",
    "    #     n = pypsa.Network(path_n)\n",
    "    #     ### Load shedding\n",
    "ind_load = [gen for gen in n.generators.index if gen.__contains__('load')]\n",
    "load_shed_sum = n.generators_t.p.loc[timespan,ind_load].sum().sum()\n",
    "outputs.append(load_shed_sum)\n",
    "load_shed_share = load_shed_sum/(n.loads_t.p.loc[timespan].sum().sum())\n",
    "outputs.append(load_shed_share)\n",
    "\n",
    "        # ### get the number of congestions\n",
    "        # lines_and_hours = len(timespan)*len(n.lines.index)\n",
    "        # # total number of times and lines when there is no congestion\n",
    "        # no_congestions = n.lines_t.p0[abs(n.lines_t.p0)/(n.lines.s_nom*n.lines.s_max_pu)==1].loc[timespan,:].isnull().sum().sum()\n",
    "        # congestions = lines_and_hours-no_congestions\n",
    "        # # kind of share of congestion event over the total possible number\n",
    "        # congestions_per = congestions/lines_and_hours\n",
    "        # # congestion hours in every hour\n",
    "        # congestion_hours_no = n.lines_t.p0[abs(n.lines_t.p0)/(n.lines.s_nom*n.lines.s_max_pu)==1].loc[timespan,:].isnull().sum(axis=1)\n",
    "        # congestion_hours = len(n.lines.index) - congestion_hours_no\n",
    "        # # this is the mean number of congested lines in every hour\n",
    "        # congestion_hours_mean = congestion_hours.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6280167903348554"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# congestions in links\n",
    "links_and_hours = len(timespan)*len(n.links.index)\n",
    "no_pos = n.links_t.p0[(n.links_t.p0)/(n.links.p_nom*n.links.p_max_pu)==1].loc[timespan,:].isnull().sum().sum()\n",
    "no_neg = n.links_t.p0[(n.links_t.p0)/(n.links.p_nom*n.links.p_min_pu)==1].loc[timespan,:].isnull().sum().sum()\n",
    "# n.links.p_min_pu # is negative but also p0 is negative when flow in opposite direction\n",
    "congestions_links = (links_and_hours - no_pos) + (links_and_hours - no_neg)\n",
    "congestions_links_per = congestions_links/links_and_hours\n",
    "congestions_links_per"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "        ### system congestion from paper in energy\n",
    "        # get average LMP in every hour\n",
    "lmp_avg = n.buses_t.marginal_price.loc[timespan,:].mean(axis=1)\n",
    "# sc_0 =  math.sqrt(1/len(n.buses.index)*(sum([(lmp_avg[year[0]] - n.buses_t.marginal_price.loc[year[0],bus])**2 for bus in n.buses.index])))\n",
    "sc_t = [math.sqrt(1/len(n.buses.index)*(sum([(lmp_avg[t] - n.buses_t.marginal_price.loc[t,bus])**2 for bus in n.buses.index]))) for t in timespan]\n",
    "sc_avg = sum(sc_t)/len(sc_t)\n",
    "        # # add to results\n",
    "        # outputs.append(congestions_per)\n",
    "        # outputs.append(congestion_hours_mean)\n",
    "outputs.append(sc_avg)\n",
    "    # assign results to dictionary\n",
    "out['zone'] = outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "# the index of dataframe will be\n",
    "ind = ['penalty/bid','abs diff corrected', 'mean abs diff','mean rel diff wrt hour 1','run time in s', 'run time in h','ofv in EUR','load shedding total in MWh', 'load shedding share of total demand', 'congestion share of total events', 'average no of congested lines per hour', 'average system congestion']\n",
    "ind_z = ['abs diff corrected', 'mean abs diff','mean rel diff wrt hour 1','ofv in EUR','load shedding total in MWh', 'load shedding share of total demand', 'average system congestion']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% for putting results in dataframe\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 7 elements, new values have 12 elements",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5548/2669877472.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mtable2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0morient\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'index'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mtable2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtable2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mtable2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mind\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mD:\\Python\\Tools\\miniconda3\\envs\\pypsa-eur\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m__setattr__\u001B[1;34m(self, name, value)\u001B[0m\n\u001B[0;32m   5476\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5477\u001B[0m             \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5478\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__setattr__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5479\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5480\u001B[0m             \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\properties.pyx\u001B[0m in \u001B[0;36mpandas._libs.properties.AxisProperty.__set__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mD:\\Python\\Tools\\miniconda3\\envs\\pypsa-eur\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m_set_axis\u001B[1;34m(self, axis, labels)\u001B[0m\n\u001B[0;32m    668\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_set_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIndex\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    669\u001B[0m         \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mensure_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 670\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_mgr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    671\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_clear_item_cache\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Python\\Tools\\miniconda3\\envs\\pypsa-eur\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36mset_axis\u001B[1;34m(self, axis, new_labels)\u001B[0m\n\u001B[0;32m    218\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    219\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mnew_len\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mold_len\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 220\u001B[1;33m             raise ValueError(\n\u001B[0m\u001B[0;32m    221\u001B[0m                 \u001B[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m                 \u001B[1;34mf\"values have {new_len} elements\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Length mismatch: Expected axis has 7 elements, new values have 12 elements"
     ]
    }
   ],
   "source": [
    "# table2 = pd.DataFrame.from_dict(out,orient='index')\n",
    "# table2 = table2.transpose()\n",
    "# table2.columns = ind"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%congestion\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "table = pd.DataFrame.from_dict(out,orient='index')\n",
    "table.columns = ind_z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "             penalty/bid  abs diff corrected  mean abs diff  \\\nzonal_shadow        bids        4.013991e+01   1.013634e-01   \n20                  bids       -7.983764e-09  -2.016102e-11   \n30                  bids        1.829628e+02   4.620273e-01   \n40                  bids       -7.591595e-09  -1.917069e-11   \n50                  bids        2.508911e+02   6.335634e-01   \n60                  bids        1.915970e+03   4.838309e+00   \n70                  bids        1.180086e+02   2.980015e-01   \n\n              mean rel diff wrt hour 1  run time in s  run time in h  \\\nzonal_shadow              1.749195e-06       23385.53       6.495981   \n20                       -3.043078e-17       23661.55       6.572653   \n30                        7.917649e-06       17840.12       4.955589   \n40                       -3.026724e-17       20205.52       5.612644   \n50                        1.081989e-05       21072.45       5.853458   \n60                        8.262819e-05       19498.92       5.416367   \n70                        5.089243e-06       23973.64       6.659344   \n\n                ofv in EUR  load shedding total in MWh  \\\nzonal_shadow  2.635893e+11                1.924431e+07   \n20            2.656342e+11                1.944426e+07   \n30                     inf                         NaN   \n40            2.635348e+11                1.923932e+07   \n50                     inf                         NaN   \n60                     inf                         NaN   \n70            2.614274e+11                1.903055e+07   \n\n              load shedding share of total demand  \\\nzonal_shadow                             0.005946   \n20                                       0.006008   \n30                                            NaN   \n40                                       0.005944   \n50                                            NaN   \n60                                            NaN   \n70                                       0.005880   \n\n              congestion share of total events  \\\nzonal_shadow                          0.029374   \n20                                    0.029484   \n30                                         NaN   \n40                                    0.029339   \n50                                         NaN   \n60                                         NaN   \n70                                    0.029480   \n\n              average no of congested lines per hour  \\\nzonal_shadow                               48.819977   \n20                                         49.002740   \n30                                               NaN   \n40                                         48.761187   \n50                                               NaN   \n60                                               NaN   \n70                                         48.994977   \n\n              average system congestion  ofv diff to smallest in Mio EUR  \\\nzonal_shadow                1123.433002                      2161.809271   \n20                          1133.562292                      4206.790278   \n30                                  NaN                              inf   \n40                          1123.559604                      2107.323043   \n50                                  NaN                              inf   \n60                                  NaN                              inf   \n70                          1130.142020                         0.000000   \n\n              ofv diff wrt smallest  \nzonal_shadow               0.008269  \n20                         0.016092  \n30                              inf  \n40                         0.008061  \n50                              inf  \n60                              inf  \n70                         0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>penalty/bid</th>\n      <th>abs diff corrected</th>\n      <th>mean abs diff</th>\n      <th>mean rel diff wrt hour 1</th>\n      <th>run time in s</th>\n      <th>run time in h</th>\n      <th>ofv in EUR</th>\n      <th>load shedding total in MWh</th>\n      <th>load shedding share of total demand</th>\n      <th>congestion share of total events</th>\n      <th>average no of congested lines per hour</th>\n      <th>average system congestion</th>\n      <th>ofv diff to smallest in Mio EUR</th>\n      <th>ofv diff wrt smallest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>zonal_shadow</th>\n      <td>bids</td>\n      <td>4.013991e+01</td>\n      <td>1.013634e-01</td>\n      <td>1.749195e-06</td>\n      <td>23385.53</td>\n      <td>6.495981</td>\n      <td>2.635893e+11</td>\n      <td>1.924431e+07</td>\n      <td>0.005946</td>\n      <td>0.029374</td>\n      <td>48.819977</td>\n      <td>1123.433002</td>\n      <td>2161.809271</td>\n      <td>0.008269</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>bids</td>\n      <td>-7.983764e-09</td>\n      <td>-2.016102e-11</td>\n      <td>-3.043078e-17</td>\n      <td>23661.55</td>\n      <td>6.572653</td>\n      <td>2.656342e+11</td>\n      <td>1.944426e+07</td>\n      <td>0.006008</td>\n      <td>0.029484</td>\n      <td>49.002740</td>\n      <td>1133.562292</td>\n      <td>4206.790278</td>\n      <td>0.016092</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>bids</td>\n      <td>1.829628e+02</td>\n      <td>4.620273e-01</td>\n      <td>7.917649e-06</td>\n      <td>17840.12</td>\n      <td>4.955589</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>inf</td>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>bids</td>\n      <td>-7.591595e-09</td>\n      <td>-1.917069e-11</td>\n      <td>-3.026724e-17</td>\n      <td>20205.52</td>\n      <td>5.612644</td>\n      <td>2.635348e+11</td>\n      <td>1.923932e+07</td>\n      <td>0.005944</td>\n      <td>0.029339</td>\n      <td>48.761187</td>\n      <td>1123.559604</td>\n      <td>2107.323043</td>\n      <td>0.008061</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>bids</td>\n      <td>2.508911e+02</td>\n      <td>6.335634e-01</td>\n      <td>1.081989e-05</td>\n      <td>21072.45</td>\n      <td>5.853458</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>inf</td>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>bids</td>\n      <td>1.915970e+03</td>\n      <td>4.838309e+00</td>\n      <td>8.262819e-05</td>\n      <td>19498.92</td>\n      <td>5.416367</td>\n      <td>inf</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>inf</td>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>bids</td>\n      <td>1.180086e+02</td>\n      <td>2.980015e-01</td>\n      <td>5.089243e-06</td>\n      <td>23973.64</td>\n      <td>6.659344</td>\n      <td>2.614274e+11</td>\n      <td>1.903055e+07</td>\n      <td>0.005880</td>\n      <td>0.029480</td>\n      <td>48.994977</td>\n      <td>1130.142020</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the difference in ofv from the smallest value\n",
    "table['ofv diff to smallest in Mio EUR'] = (table['ofv in EUR']-table['ofv in EUR'].min())/1e6\n",
    "# calculate also th epercentage difference\n",
    "table['ofv diff wrt smallest'] = (table['ofv in EUR']-table['ofv in EUR'].min())/table['ofv in EUR'].min()\n",
    "table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "save_table = 'D:\\Python\\PyPSA/Luca/nodal_zonal_model/hydro/hpc_results/last_results/hour0/zonal_results.csv'\n",
    "table.to_csv(save_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% export results table\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "           0\n(1, test)  3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>(1, test)</th>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = {}\n",
    "out[(1,'test')] = 3\n",
    "table = pd.DataFrame.from_dict(out,orient='index')\n",
    "table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}